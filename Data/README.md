# Dataset Structure

This README describes the expected structure of any dataset such that it can be used by the pipeline.

## Quick Start

```
Data/
  my_dataset/
  
    # Required Minimum
    # Given well-enumerated image sequence
    1.png
    2.png
    3.png
    ...
    
    # Normalized-well enumered images
    # Generated by Source/compute_flows/
    1.ppm # 1st normalized image
    2.ppm
    3.ppm
    ...
    
    # flow fields generated by using the LDOF method
    # Generated by Source/compute_flows/
    ldof/
      # Backward flow fields
      # Generated by Source/compute_flows/
      bwf_2LDOF.flo # flow 2 -> 1
      bwf_3LDOF.flo # flow 3 -> 2
      ...
    
      # Forward flows
      # Generated by Source/compute_flows/
      fwf_1LDOF.flo # flow 1 -> 2
      fwf_2LDOF.flo # flow 2 -> 3
      ...
    
    # flow files generated by another supported flow method
    other_flow_file_dir/
      flow files
      ...
    
 
    
    # Optional (well-enumerated) depth maps input
    depths/
      1.png
      2.png
      ...
    
    # Optional meta information
    # Used when using depth cues
    meta/
      
      # extrinsic camera parameters: align depth-and color camera
      calib.txt
      
      # image resolution
      dataset.txt
  
    # Sorted filename list of input data used by pipeline
    # Generated by Source/compute_flows/
    used_input.txt  
    
```

## Detailed explanation

Every available dataset has to be contained in its own subfolder within `./Data/`. 

A **minimal** valid **dataset** consists of a coherently **well-enumerated** (color) image sequence (i.e the frames of a video).
In our case, Well-enumerated means that **n-th frame** of the image sequence has the **name** **n**.
Note that the pipeline offers a renaming script which renames the images files that they are _well-enumerated_.
This script can be found at `.Source/normalize_sensor_data/`.

Currently, **.png** and **.ppm** images are supported.

**Example**: Assume we have a dataset called _foo_, consiting of 3 png images, called `1.png, 2.png, 3.png`. 
Then we have to:

1. Create a subfolder `./Data/foo/`.
2. Put the png images into `foo/`.
