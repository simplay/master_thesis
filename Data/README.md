# Dataset Structure

This README describes the expected structure of any dataset such that it can be used by the pipeline.

## Quick Start

+ Complete valid dataset structure (see below)
+ Optionally, re-enumerate images by using the scripts in `.Source/normalize_sensor_data/`.
+ Run `.Source/compute_flows/run.sh` to generate the optical flow fields. Those will be stored in the dataset's root directory.
+ Run `.Source/init_data/init_data.m` to generated all required pipeline inputs. 

```
Data/
  my_dataset/
  
    # Required Minimum
    # Given well-enumerated image sequence
    1.png
    2.png
    3.png
    ...
    
    # Normalized-well enumered images
    # Generated by Source/compute_flows/
    1.ppm # 1st normalized image
    2.ppm
    3.ppm
    ...
    
    # flow fields generated by using the LDOF method
    # Generated by Source/compute_flows/
    ldof/
      # Backward flow fields
      # Generated by Source/compute_flows/
      bwf_2LDOF.flo # flow 2 -> 1
      bwf_3LDOF.flo # flow 3 -> 2
      ...
    
      # Forward flows
      # Generated by Source/compute_flows/
      fwf_1LDOF.flo # flow 1 -> 2
      fwf_2LDOF.flo # flow 2 -> 3
      ...
    
    # flow files generated by another supported flow method
    other_flow_file_dir/
      flow files
      ...
    
 
    
    # Optional (well-enumerated) depth maps input
    depths/
      1.png
      2.png
      ...
    
    # Optional meta information
    # Used when using depth cues
    meta/
      
      # extrinsic camera parameters: align depth-and color camera
      calib.txt
      
      # image resolution
      dataset.txt
  
    # Sorted filename list of input data used by pipeline
    # Generated by Source/compute_flows/
    used_input.txt  
    
```

## Detailed explanation

Every available dataset has to be contained in its own subfolder within `./Data/`. 

A **minimal** valid **dataset** consists of a coherently **well-enumerated** (color) image sequence (i.e the frames of a video).
In our case, Well-enumerated means that **n-th frame** of the image sequence has the **name** **n**.
Note that the pipeline offers a renaming script which renames the images files that they are _well-enumerated_.
This script can be found at `.Source/normalize_sensor_data/`.

Currently, **.png** and **.ppm** images are supported.

**Example**: Assume we have a dataset called _foo_, consiting of 3 png images, called `1.png, 2.png, 3.png`. 
Then we have to:

1. Create a subfolder `./Data/foo/`.
2. Put the png images into `foo/`.
 
After having defined a valid dataset for which we want to extract its motion segmentation, we initially have to generate its optical flow fields by running `.Source/compute_flows/run.sh`. This script guides the user through the generation process. Please also read the corresponding readme located at `.Source/compute_flows/`.

The followind additional cues can be fed into the pipeline, which enables additional, accurater motion segmentation extraction modes within the pipeline:

+ **Depth fields**: One depth field per color image. Each such depth field is supposed to be well-enumerated and should be put into `./Data/my_dataset/depth`.
+ **Extrinsic Camera Clibration Parameters**: Put a file called `Dataset/my_dataset/meta/calib.txt`. The content of such a file looks like the following:

```
line1: Dimensions x,y
line2: rgb inntrinsic params: focal length x y
line3: rgb inntrinsic params: principal point x y

line4: empty line

line5: Dimensions x,y
line6: depth intrinsic params: focal length x y
line7: depth intrinsic params: principal point x y

line8: empty line

# The Extrinsic parameters 4x3 matrix describing
the transformation from color to depth

line9: 1st row of the extrinsic 4x3 matrix
line10: 2nd row of the extrinsic 4x3 matrix
line11: 3rd row of the extrinsic 4x3 matrix

```

**Example calib.txt** file: 

```
640 480
504.261 503.905
352.457 272.202

640 480
573.71 574.394
346.471 249.031

0.999749 0.00518867 0.0217975 0.0243073
-0.0051649 0.999986 -0.0011465 -0.000166518
-0.0218031 0.00103363 0.999762 0.0151706

```

By Running the a valid dataset on `./Source/init_data/init_data.m` we will generate all the required pipeline inputs. Please read the corresponding docs of the script `init_data.m`. 
