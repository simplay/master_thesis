@Article{Hs81,
  author       = "Berthold K.P. Horn and Brian G. Schunck",
  tile        = "Determining Optical Flow",
  journal      = "Artificial Intelligence",
  number       = "1-3",
  volume       = "17",
  pages        = "185-203",
  month        = "August.",
  year         = "1981",
  url          = "http://www.sciencedirect.com/science/article/pii/0004370281900242"
}

@Article{Bro11a,
  author       = "T. Brox and J. Malik",
  title        = "Large displacement optical flow: descriptor matching in variational motion estimation",
  journal      = "IEEE Transactions on Pattern Analysis and Machine Intelligence",
  number       = "3",
  volume       = "33",
  pages        = "500-513",
  year         = "2011",
  url          = "http://lmb.informatik.uni-freiburg.de//Publications/2011/Bro11a"
}

@Article{OB14b,
  author       = "P. Ochs and J. Malik and T. Brox",
  title        = "Segmentation of moving objects by long term video analysis",
  journal      = "IEEE Transactions on Pattern Analysis and Machine Intelligence",
  number       = "6",
  volume       = "36",
  pages        = "1187 - 1200",
  month        = "Jun",
  year         = "2014",
  note         = "Preprint",
  url          = "http://lmb.informatik.uni-freiburg.de//Publications/2014/OB14b"
}

@InProceedings{KB15b,
  author       = "M. Keuper and B. Andres and T. Brox",
  title        = "Motion Trajectory Segmentation via Minimum Cost Multicuts",
  booktitle    = "IEEE International Conference on Computer Vision (ICCV)",
  year         = "2015",
  url          = "http://lmb.informatik.uni-freiburg.de//Publications/2015/KB15b"
}

@InProceedings{OB12,
  author       = "P.Ochs and T.Brox",
  title        = "Higher Order Motion Models and Spectral Clustering",
  booktitle    = "IEEE International Conference on Computer Vision and Pattern Recognition (CVPR)",
  year         = "2012",
  url          = "http://lmb.informatik.uni-freiburg.de//Publications/2012/OB12"
}

@InProceedings{OB11,
  author       = "P.Ochs and T.Brox",
  title        = "Object segmentation in video: a hierarchical variational approach for turning point trajectories into dense regions",
  booktitle    = "IEEE International Conference on Computer Vision (ICCV)",
  year         = "2011",
  url          = "http://lmb.informatik.uni-freiburg.de//Publications/2011/OB11"
}

@InProceedings{Bro10e,
  author       = "N. Sundaram and T. Brox and K. Keutzer",
  title        = "Dense point trajectories by GPU-accelerated large displacement optical flow",
  booktitle    = "European Conference on Computer Vision (ECCV)",
  series       = "Lecture Notes in Computer Science",
  month        = "Sept.",
  year         = "2010",
  publisher    = "Springer",
  url          = "http://lmb.informatik.uni-freiburg.de//Publications/2010/Bro10e"
}

@InProceedings{Bro10c,
  author       = "T.Brox and J.Malik",
  title        = "Object segmentation by long term analysis of point trajectories",
  booktitle    = "European Conference on Computer Vision (ECCV)",
  series       = "Lecture Notes in Computer Science",
  month        = "Sept.",
  year         = "2010",
  publisher    = "Springer",
  url          = "http://lmb.informatik.uni-freiburg.de//Publications/2010/Bro10c"
}

@InProceedings{Bro09b,
  author       = "T. Brox and C. Bregler and J. Malik",
  title        = "Large displacement optical flow",
  booktitle    = "IEEE International Conference on Computer Vision and Pattern Recognition (CVPR)",
  month        = "Jun.",
  year         = "2009",
  url          = "http://lmb.informatik.uni-freiburg.de//Publications/2009/Bro09b"
}

@Article{Bro09,
  author       = "T. Brox and D. Cremers",
  title        = "On local region models and a statistical interpretation of the piecewise smooth Mumford-Shah functional",
  journal      = "International Journal of Computer Vision",
  number       = "2",
  volume       = "84",
  pages        = "184-193",
  month        = "Jun.",
  year         = "2009",
  url          = "http://lmb.informatik.uni-freiburg.de//Publications/2009/Bro09"
}

@Article{Ker70,
  author       = "B. W. Kernighan and S. Lin",
  title        = "An efficient heuristic procedure for partitioning graphs
",
  journal      = "The Bell System Technical Journal",
  number       = "2",
  volume       = "49",
  pages        = "291-307",
  month        = "Feb.",
  year         = "1970",
  url          = "http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6771089"
}

@Article{Deq10,
  author       = "Deqing Sun and Brown University and Stefan Roth and Michael J.Black",
  title        = "Secrets of optical flow estimation and their principles
",
  journal      = "Computer Vision and Pattern Recognition (CVPR) 2010",
  pages        = "2432-2439",
  month        = "June",
  year         = "2010"
}

@Article{Deq15,
  author       = "D. Sun, E. B. Sudderth, and H. Pfister ",
  title        = "Layered RGBD Scene Flow Estimation",
  journal      = "Computer Vision and Pattern Recognition (CVPR) 2015",
  pages        = "548 - 556 ",
  month        = "June",
  year         = "2015"
}

@Article{Deq12,
  author       = "D. Sun, E. B. Sudderth, and M. J. Black",
  tile        = "Layered Segmentation and Optical Flow Estimation over Time",
  journal      = "Computer Vision and Pattern Recognition (CVPR) 2012",
  year         = "2012"
}

@Article{Deq14,
  author       = "Deqing Sun, Stefan Roth, Michael J. Black",
  title        = "A Quantitative Analysis of Current Practices in Optical Flow Estimation and the Principles Behind Them
",
  journal      = "Computer Vision and Pattern Recognition (CVPR) 2010",
  number       = "2",
  volume       = "106",
  pages        = "115-137",
  month        = "January",
  year         = "2014"
}

@Article{Lux07,
  author       = "Ulrike von Luxburg",
  title        = "A tutorial on spectral clustering",
  journal      = "Statistics and Computing",
  number       = "4",
  volume       = "17",
  pages        = "395-416",
  month        = "December",
  year         = "2007"
}

@InProceedings{Bro14,
  author       = "J. Quiroga and T. Brox and F. Devernay and J. Crowley",
  title        = "Dense semi-rigid scene flow estimation from RGBD images",
  booktitle    = "European Conference on Computer Vision (ECCV)",
  year         = "2014",
  url          = "http://lmb.informatik.uni-freiburg.de//Publications/2014/Bro14"
}

@Article{Herbst13,
  author       = "Evan Herbst, Xiaofeng Ren and Dieter Fox",
  title        = "RGB-D flow: Dense 3-D motion estimation using color and depth",
  journal      = "ICRA",
  pages        = "2276-2282",
  year         = "2013"
}


@Article{Cav05,
  author       = "A. Cavallaro ; Dept. of Electron. Eng., Univ. of London, UK ; O. Steiger ; T. Ebrahimi",
  title        = "Tracking video objects in cluttered background",
  journal      = "IEEE Transactions on Circuits and Systems for Video Technology",
  number       = "4",
  volume       = "15",
  pages        = "575 - 584",
  year         = "2005"
}

@Article{Li07,
  author       = "Renjie Li ; Shanghai Jiao Tong Univ., Shanghai ; Songyu Yu ; Xiaokang Yang",
  title        = "Efficient Spatio-temporal Segmentation for Extracting Moving Objects in Video Sequences",
  journal      = "IEEE Transactions on Consumer Electronics",
  number       = "3",
  volume       = "53",
  pages        = "1161 - 1167",
  month        = "August",
  year         = "2007"
}

@Article{Col07,
  author       = "A. Colombari, A. Fusiello, V. Murino",
  title        = "Segmentation and tracking of multiple video objects",
  journal      = "Pattern Recognition",
  number       = "4",
  volume       = "40",
  pages        = "1307–1317",
  month        = "April",
  year         = "2007"
}

@Article{Cre05,
  author       = "Daniel Cremers, Stefano Soatto",
  title        = "Motion Competition: A Variational Approach to Piecewise Parametric Motion Segmentation",
  journal      = "International Journal of Computer Vision",
  number       = "3",
  volume       = "62",
  pages        = "249-265",
  month        = "May",
  year         = "2005"
}

@InProceedings{Fulkerson2009,
  author =  {Fulkerson, B.  and Vedaldi, A.  and Soatto, S.},
  title =   {Class Segmentation and Object Localization with Superpixel Neighborhoods},
  booktitle =   {Proceedings of the International Conference on Computer Vision},
  year =  {2009},
  month =   {October}
}

@article{chambolle2011first,
  title={A first-order primal-dual algorithm for convex problems with applications to imaging},
  author={Chambolle, Antonin and Pock, Thomas},
  journal={Journal of Mathematical Imaging and Vision},
  volume={40},
  number={1},
  pages={120--145},
  year={2011},
  publisher={Springer}
}

@article{chambolle2004algorithm,
  title={An algorithm for total variation minimization and applications},
  author={Chambolle, Antonin},
  journal={Journal of Mathematical imaging and vision},
  volume={20},
  number={1-2},
  pages={89--97},
  year={2004},
  publisher={Springer}
}

@article{Shepard87,
  title={Toward a Universal Law of Generalization for Psychological Science},
  author={Roger N. Shepard},
  journal={Science, New Series},
  volume={237},
  number={4820},
  pages={1317-1323},
  year={1987},
  mont={September}
  publisher={American Association for the Advancement of Science}
}

@article{DBLP:journals/corr/EigenPF14,
  author    = {David Eigen and
               Christian Puhrsch and
               Rob Fergus},
  title     = {Depth Map Prediction from a Single Image using a Multi-Scale Deep
               Network},
  journal   = {CoRR},
  volume    = {abs/1406.2283},
  year      = {2014},
  url       = {http://arxiv.org/abs/1406.2283},
  timestamp = {Tue, 01 Jul 2014 11:58:08 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/EigenPF14},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@InProceedings{OB12,
  author       = "P.Ochs and T.Brox",
  title        = "Higher Order Motion Models and Spectral Clustering",
  booktitle    = "IEEE International Conference on Computer Vision and Pattern Recognition (CVPR)",
  year         = "2012",
  url          = "http://lmb.informatik.uni-freiburg.de//Publications/2012/OB12"
}

@Article{vonLuxburg2007,
author="von Luxburg, Ulrike",
title="A tutorial on spectral clustering",
journal="Statistics and Computing",
year="2007",
volume="17",
number="4",
pages="395--416",
abstract="In recent years, spectral clustering has become one of the most popular modern clustering algorithms. It is simple to implement, can be solved efficiently by standard linear algebra software, and very often outperforms traditional clustering algorithms such as the k-means algorithm. On the first glance spectral clustering appears slightly mysterious, and it is not obvious to see why it works at all and what it really does. The goal of this tutorial is to give some intuition on those questions. We describe different graph Laplacians and their basic properties, present the most common spectral clustering algorithms, and derive those algorithms from scratch by several different approaches. Advantages and disadvantages of the different spectral clustering algorithms are discussed.",
issn="1573-1375",
doi="10.1007/s11222-007-9033-z",
url="http://dx.doi.org/10.1007/s11222-007-9033-z"
}

@article{Jeg09,
  author    = {Stefanie Jegelka and
               Jeff Bilmes},
  title     = {Notes on graph cuts with submodular edge weights},
  year      = {2009}
}

@article{Stoer:1997:SMA:263867.263872,
 author = {Stoer, Mechthild and Wagner, Frank},
 title = {A Simple Min-cut Algorithm},
 journal = {J. ACM},
 issue_date = {July 1997},
 volume = {44},
 number = {4},
 month = jul,
 year = {1997},
 issn = {0004-5411},
 pages = {585--591},
 numpages = {7},
 url = {http://doi.acm.org/10.1145/263867.263872},
 doi = {10.1145/263867.263872},
 acmid = {263872},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {min-cut}
} 

@article{Fe08,
author = { Doron Feldman, Daphna Weinshall},
title = {Motion Segmentation and Depth Ordering Using an Occlusion Detector},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
volume = {30},
number = {7},
month = jul,
year = {2008},
issn = {0162-8828},
pages = {1171-1185 }
}

@InProceedings{Mi98,
  author       = "Mingqi Kong, B. K. Ghosh, V. M. Wickerhauser",
  title        = "Spatio-temporal continuous wavelet transforms for motion-based segmentation in real image sequences",
  booktitle    = "Image Processing, 1998. ICIP 98. Proceedings.",
  year         = "1998"
}

@article{WISKOTT19991751,
title = "Segmentation from motion: combining Gabor- and Mallat-wavelets to overcome the aperture and correspondence problems",
journal = "Pattern Recognition",
volume = "32",
number = "10",
pages = "1751 - 1766",
year = "1999",
note = "",
issn = "0031-3203",
doi = "http://dx.doi.org/10.1016/S0031-3203(98)00179-4",
url = "http://www.sciencedirect.com/science/article/pii/S0031320398001794",
author = "Laurenz Wiskott",
keywords = "Segmentation from motion",
keywords = "Gabor-wavelet transform",
keywords = "Mallat-wavelet transform",
keywords = "Integration",
keywords = "Motion hypotheses",
abstract = "A new method for segmentation from motion is presented, which is designed to be part of a general object-recognition system. The key idea is to integrate information from Gabor- and Mallat-wavelet transforms of an image sequence to overcome the aperture and the correspondence problem. It is assumed that objects move fronto-parallel. Gabor-wavelet responses allow accurate estimation of image flow vectors with low spatial resolution. A histogram over this image flow field is evaluated and its local maxima provide a set of motion hypotheses. These serve to reduce the correspondence problem occurring in utilizing the Mallat-wavelet transform, which provides the required high spatial resolution in segmentation. Segmentation reliability is improved by integration over time. The system can segment several small, disconnected, and openworked objects, such as dot patterns. Several examples demonstrate the performance of the system and show that the algorithm behaves reasonably well, even if the assumption of fronto-parallel motion is not met."
}

@Article{PawanKumar2008,
author="Pawan Kumar, M.
and Torr, P. H. S.
and Zisserman, A.",
title="Learning Layered Motion Segmentations of Video",
journal="International Journal of Computer Vision",
year="2008",
volume="76",
number="3",
pages="301--319",
abstract="We present an unsupervised approach for learning a layered representation of a scene from a video for motion segmentation. Our method is applicable to any video containing piecewise parametric motion. The learnt model is a composition of layers, which consist of one or more segments. The shape of each segment is represented using a binary matte and its appearance is given by the rgb value for each point belonging to the matte. Included in the model are the effects of image projection, lighting, and motion blur. Furthermore, spatial continuity is explicitly modeled resulting in contiguous segments. Unlike previous approaches, our method does not use reference frame(s) for initialization. The two main contributions of our method are: (i)Â A novel algorithm for obtaining the initial estimate of the model by dividing the scene into rigidly moving components using efficient loopy belief propagation; and (ii)Â Refining the initial estimate using $\alpha$                        $\beta$-swap and $\alpha$-expansion algorithms, which guarantee a strong local minima. Results are presented on several classes of objects with different types of camera motion, e.g. videos of a human walking shot with static or translating cameras. We compare our method with the state of the art and demonstrate significant improvements.",
issn="1573-1405",
doi="10.1007/s11263-007-0064-x",
url="http://dx.doi.org/10.1007/s11263-007-0064-x"
}

@Article{Tomasi1992,
author="Tomasi, Carlo
and Kanade, Takeo",
title="Shape and motion from image streams under orthography: a factorization method",
journal="International Journal of Computer Vision",
year="1992",
volume="9",
number="2",
pages="137--154",
abstract="Inferring scene geometry and camera motion from a stream of images is possible in principle, but is an ill-conditioned problem when the objects are distant with respect to their size. We have developed a factorization method that can overcome this difficulty by recovering shape and motion under orthography without computing depth as an intermediate step.",
issn="1573-1405",
doi="10.1007/BF00129684",
url="http://dx.doi.org/10.1007/BF00129684"
}

@Inbook{Yan2006,
author="Yan, Jingyu
and Pollefeys, Marc",
editor="Leonardis, Ale{\v{s}}
and Bischof, Horst
and Pinz, Axel",
title="A General Framework for Motion Segmentation: Independent, Articulated, Rigid, Non-rigid, Degenerate and Non-degenerate",
bookTitle="Computer Vision -- ECCV 2006: 9th European Conference on Computer Vision, Graz, Austria, May 7-13, 2006, Proceedings, Part IV",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="94--106",
isbn="978-3-540-33839-0",
doi="10.1007/11744085_8",
url="http://dx.doi.org/10.1007/11744085_8"
}

@Article{Costeira1998,
author="Costeira, J. Paulo and Kanade, Takeo",
title="A Multibody Factorization Method for Independently Moving Objects",
journal="International Journal of Computer Vision",
year="1998",
volume="29",
number="3",
pages="159--179",
abstract="The structure-from-motion problem has been extensively studied in the field of computer vision. Yet, the bulk of the existing work assumes that the scene contains only a single moving object. The more realistic case where an unknown number of objects move in the scene has received little attention, especially for its theoretical treatment. In this paper we present a new method for separating and recovering the motion and shape of multiple independently moving objects in a sequence of images. The method does not require prior knowledge of the number of objects, nor is dependent on any grouping of features into an object at the image level. For this purpose, we introduce a mathematical construct of object shapes, called the shape interaction matrix, which is invariant to both the object motions and the selection of coordinate systems. This invariant structure is computable solely from the observed trajectories of image features without grouping them into individual objects. Once the matrix is computed, it allows for segmenting features into objects by the process of transforming it into a canonical form, as well as recovering the shape and motion of each object. The theory works under a broad set of projection models (scaled orthography, paraperspective and affine) but they must be linear, so it excludes projective ``cameras''.",
issn="1573-1405",
doi="10.1023/A:1008000628999",
url="http://dx.doi.org/10.1023/A:1008000628999"
}

@Article{Chopra1993,
author="Chopra, Sunil
and Rao, M. R.",
title="The partition problem",
journal="Mathematical Programming",
year="1993",
volume="59",
number="1",
pages="87--115",
abstract="In this paper we describe several forms of thek-partition problem and give integer programming formulations of each case. The dimension of the associated polytopes and some basic facets are identified. We also give several valid and facet defining inequalities for each of the polytopes.",
issn="1436-4646",
doi="10.1007/BF01581239",
url="http://dx.doi.org/10.1007/BF01581239"
}

@article{BoydVanderberg2004,
    author  = "tephen Boyd and Lieven Vandenberghe",
    title   = "Convex Optimization",
    year    = "2004",
    isbn	= "0521833787"
    journal = "Cambridge University Press"
}
@Article{Dahan2012,
author="Dahan, Meir Johnathan
and Chen, Nir
and Shamir, Ariel
and Cohen-Or, Daniel",
title="Combining color and depth for enhanced image segmentation and retargeting",
journal="The Visual Computer",
year="2012",
volume="28",
number="12",
pages="1181--1193",
abstract="As depth cameras become more popular, pixel depth information becomes easier to obtain. This information can clearly enhance many image processing applications. However, combining depth and color information is not straightforward as these two signals can have different noise characteristics, differences in resolution, and their boundaries do not generally agree. We present a technique that combines depth and color image information from real devices in synergy. In particular, we focus on combining them to improve image segmentation. We use color information to fill and clean depth and use depth to enhance color image segmentation. We demonstrate the utility of the combined segmentation for extracting layers and present a novel image retargeting algorithm for layered images.",
issn="1432-2315",
doi="10.1007/s00371-011-0667-7",
url="http://dx.doi.org/10.1007/s00371-011-0667-7"
}
@Article{Baker2011,
author="Baker, Simon
and Scharstein, Daniel
and Lewis, J. P.
and Roth, Stefan
and Black, Michael J.
and Szeliski, Richard",
title="A Database and Evaluation Methodology for Optical Flow",
journal="International Journal of Computer Vision",
year="2011",
volume="92",
number="1",
pages="1--31",
abstract="The quantitative evaluation of optical flow algorithms by Barron et al. (1994) led to significant advances in performance. The challenges for optical flow algorithms today go beyond the datasets and evaluation methods proposed in that paper. Instead, they center on problems associated with complex natural scenes, including nonrigid motion, real sensor noise, and motion discontinuities. We propose a new set of benchmarks and evaluation methods for the next generation of optical flow algorithms. To that end, we contribute four types of data to test different aspects of optical flow algorithms: (1)Â sequences with nonrigid motion where the ground-truth flow is determined by tracking hidden fluorescent texture, (2)Â realistic synthetic sequences, (3)Â high frame-rate video used to study interpolation error, and (4)Â modified stereo sequences of static scenes. In addition to the average angular error used by Barron etÂ al., we compute the absolute flow endpoint error, measures for frame interpolation error, improved statistics, and results at motion discontinuities and in textureless regions. In October 2007, we published the performance of several well-known methods on a preliminary version of our data to establish the current state of the art. We also made the data freely available on the web at                   http://vision.middlebury.edu/flow/                                  . Subsequently a number of researchers have uploaded their results to our website and published papers using the data. A significant improvement in performance has already been achieved. In this paper we analyze the results obtained to date and draw a large number of conclusions from them.",
issn="1573-1405",
doi="10.1007/s11263-010-0390-2",
url="http://dx.doi.org/10.1007/s11263-010-0390-2"
}
@article{TsaiBMVC10,
   author = {David Tsai and Matthew Flagg and James M.Rehg},
   title = {Motion Coherent Tracking with Multi-label MRF optimization},
   journal = {BMVC},
   year = {2010},
}  









